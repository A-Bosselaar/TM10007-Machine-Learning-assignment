{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing data**\n",
    "In this file, the preprocessing of the data is performed.\n",
    "\n",
    "### Feature correlation for determining number of redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix, roc_auc_score\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Caculate the correlation matrix\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Identify highly correlated features\u001b[39;00m\n\u001b[0;32m      9\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.88\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Caculate the correlation matrix\n",
    "correlation_matrix = features.corr()\n",
    "\n",
    "#Identify highly correlated features\n",
    "threshold = 0.88\n",
    "upper = correlation_matrix.where( \n",
    "    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)) #only upper triangle of the matrix (to avoid checking each pair twice)\n",
    "\n",
    "to_drop = set()\n",
    "for column in upper.columns:\n",
    "    high_corr = upper[column][abs(upper[column]) > threshold].index.tolist() # checks for correlation above the threshold\n",
    "    for correlated_feature in high_corr:\n",
    "        if correlated_feature not in to_drop and column not in to_drop:\n",
    "            to_drop.add(correlated_feature)\n",
    "\n",
    "print(f\"Number of features with correlation to drop (one per correlated pair for which correlation > {threshold}): {len(to_drop)}\")\n",
    "\n",
    "# Drop redundant features\n",
    "subset_of_features_reduced = subset_of_features.drop(columns=to_drop)\n",
    "print(f\"Number of features that remain: {len(subset_of_features_reduced.columns)}\")\n",
    "\n",
    "# Splitting the data into training, validation and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(subset_of_features_reduced, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "\n",
    "# Train Random Forest with class balancing to determine optimal threshold\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  \n",
    ")\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf_model.predict(x_val)\n",
    "y_prob = rf_model.predict_proba(x_val)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_val, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of threshold for dropping correlated features\n",
    "correlation_data = {\n",
    "    'threshold': [0.85, 0.87, 0.88, 0.9, 0.95, 0.99],\n",
    "    'features_remaining': [1530, 1896, 2069, 2521, 4231, 7929],\n",
    "    'f1_score_0': [0.91, 0.91, 0.91, 0.91, 0.91, 0.90],\n",
    "    'f1_score_1': [0.15, 0.15, 0.22, 0.22, 0.22, 0.08],\n",
    "}\n",
    "correlation_df = pd.DataFrame(correlation_data)\n",
    "\n",
    "# Create main plot with secondary y-axis\n",
    "fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Plot F1 scores\n",
    "ax1.plot(correlation_df['threshold'], correlation_df['f1_score_0'], marker='o', label='F1 Score - Class 0', color='blue')\n",
    "ax1.plot(correlation_df['threshold'], correlation_df['f1_score_1'], marker='o', label='F1 Score - Class 1', color='green')\n",
    "ax1.set_xlabel(\"Correlation Threshold\")\n",
    "ax1.set_ylabel(\"F1 Score\")\n",
    "ax1.legend(loc='upper left', bbox_to_anchor=(0, 0.9))\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot features remaining on second y-axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(correlation_df['threshold'], correlation_df['features_remaining'], marker='s', linestyle='--', color='gray', label='Features Remaining')\n",
    "ax2.set_ylabel(\"Number of Features\")\n",
    "ax2.legend(loc='upper right', bbox_to_anchor=(1, 0.9))\n",
    "\n",
    "# Title and layout\n",
    "plt.title(\"F1 Scores and Number of Features vs Correlation Threshold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
