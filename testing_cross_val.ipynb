{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f25b5fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples: 827\n",
      "The number of columns: 9001\n"
     ]
    }
   ],
   "source": [
    "# Run this to use from colab environment\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with zipfile.ZipFile('ecg/ecg_data.zip', 'r') as zip_ref: #TODO: let hierop voor inleveren\n",
    "    zip_ref.extractall('ecg')\n",
    "\n",
    "data = pd.read_csv('ecg/ecg_data.csv', index_col=0)\n",
    "\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of columns: {len(data.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93ed5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits features en labels\n",
    "X = data.iloc[:, :-1].values  # Alle kolommen behalve de laatste zijn de features\n",
    "y = data.iloc[:, -1].values   # De laatste kolom is de label (0 of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70ed1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_cv_feature_selection_with_model_optimization(X_train, y_train, k_features=2100):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "    from sklearn.metrics import f1_score\n",
    "    from scipy import stats\n",
    "    import numpy as np\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    method_scores = {\n",
    "        'ttest': {'normal': [], 'abnormal': []},\n",
    "        'kbest': {'normal': [], 'abnormal': []},\n",
    "        'rf': {'normal': [], 'abnormal': []},\n",
    "        'mi': {'normal': [], 'abnormal': []}\n",
    "    }\n",
    "\n",
    "    def select_features(method, X_tr, y_tr):\n",
    "        if method == 'ttest':\n",
    "            p_values = [stats.ttest_ind(X_tr[y_tr == 0, i], X_tr[y_tr == 1, i])[1]\n",
    "                        for i in range(X_tr.shape[1])]\n",
    "            return np.argsort(p_values)[:k_features]\n",
    "        elif method == 'kbest':\n",
    "            skb = SelectKBest(score_func=f_classif, k=k_features)\n",
    "            skb.fit(X_tr, y_tr)\n",
    "            return skb.get_support(indices=True)\n",
    "        elif method == 'rf':\n",
    "            rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            rf.fit(X_tr, y_tr)\n",
    "            return np.argsort(rf.feature_importances_)[-k_features:]\n",
    "        elif method == 'mi':\n",
    "            mi = mutual_info_classif(X_tr, y_tr)\n",
    "            return np.argsort(mi)[-k_features:]\n",
    "\n",
    "    for method in method_scores.keys():\n",
    "        print(f\"\\n Evaluating Feature Selection: {method}\")\n",
    "        for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_tr = scaler.fit_transform(X_tr)\n",
    "            X_val = scaler.transform(X_val)\n",
    "\n",
    "            selected_idx = select_features(method, X_tr, y_tr)\n",
    "            X_tr_sel = X_tr[:, selected_idx]\n",
    "            X_val_sel = X_val[:, selected_idx]\n",
    "\n",
    "            best_f1_normal = 0\n",
    "            best_f1_abnormal = 0\n",
    "            for depth in [5, 10, 20]:\n",
    "                rf = RandomForestClassifier(max_depth=depth, n_estimators=100, random_state=42)\n",
    "                rf.fit(X_tr_sel, y_tr)\n",
    "                preds = rf.predict(X_val_sel)\n",
    "                f1s = f1_score(y_val, preds, average=None, labels=[0, 1])\n",
    "                best_f1_normal = max(best_f1_normal, f1s[0])\n",
    "                best_f1_abnormal = max(best_f1_abnormal, f1s[1])\n",
    "\n",
    "            method_scores[method]['normal'].append(best_f1_normal)\n",
    "            method_scores[method]['abnormal'].append(best_f1_abnormal)\n",
    "\n",
    "        # Summary per method\n",
    "        f1_normal = np.mean(method_scores[method]['normal'])\n",
    "        f1_abnormal = np.mean(method_scores[method]['abnormal'])\n",
    "        print(f\"Normal (0) F1:   {f1_normal:.4f}\")\n",
    "        print(f\"Abnormal (1) F1: {f1_abnormal:.4f}\")\n",
    "\n",
    "    print(\"\\n Summary of All Feature Selection Methods:\")\n",
    "    for method in method_scores.keys():\n",
    "        n_avg = np.mean(method_scores[method]['normal'])\n",
    "        a_avg = np.mean(method_scores[method]['abnormal'])\n",
    "        print(f\"{method:>10} → Normal F1: {n_avg:.4f} | Abnormal F1: {a_avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b90cd56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating Feature Selection: ttest\n",
      "Normal (0) F1:   0.9206\n",
      "Abnormal (1) F1: 0.3499\n",
      "\n",
      " Evaluating Feature Selection: kbest\n",
      "Normal (0) F1:   0.9183\n",
      "Abnormal (1) F1: 0.3054\n",
      "\n",
      " Evaluating Feature Selection: rf\n",
      "Normal (0) F1:   0.9163\n",
      "Abnormal (1) F1: 0.2762\n",
      "\n",
      " Evaluating Feature Selection: mi\n",
      "Normal (0) F1:   0.9177\n",
      "Abnormal (1) F1: 0.2965\n",
      "\n",
      " Summary of All Feature Selection Methods:\n",
      "     ttest → Normal F1: 0.9206 | Abnormal F1: 0.3499\n",
      "     kbest → Normal F1: 0.9183 | Abnormal F1: 0.3054\n",
      "        rf → Normal F1: 0.9163 | Abnormal F1: 0.2762\n",
      "        mi → Normal F1: 0.9177 | Abnormal F1: 0.2965\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Run feature selection + RF evaluation across inner folds\n",
    "inner_cv_feature_selection_with_model_optimization(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5c332af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def outer_cv_pipeline_rf(X, y, feature_selection_method, k_features=2100):\n",
    "    # Outer CV Split\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Randomized Search for Random Forest\n",
    "    def random_search_rf(X_tr, y_tr):\n",
    "        rf = RandomForestClassifier(random_state=42)\n",
    "        param_dist = {\n",
    "            'n_estimators': [100],\n",
    "            'max_depth': [5],\n",
    "            'min_samples_split': [2],\n",
    "            'min_samples_leaf': [1],\n",
    "        }\n",
    "        random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=1, cv=3, random_state=42, n_jobs=-1)\n",
    "        random_search.fit(X_tr, y_tr)\n",
    "        return random_search.best_estimator_\n",
    "\n",
    "    # Initialize lists to store results for each fold\n",
    "    rf_results_normal = []\n",
    "    rf_results_abnormal = []\n",
    "\n",
    "    # Outer Cross-validation loop\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # --- Scale the data (fit on training, transform on both train/test) ---\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)  # Fit on training set\n",
    "        X_test_scaled = scaler.transform(X_test)        # Use the same scaler for the test set\n",
    "\n",
    "        # --- Feature Selection using the specified method ---\n",
    "        selected_idx = feature_selection_method(X_train_scaled, y_train, k_features)\n",
    "        X_train_sel = X_train_scaled[:, selected_idx]\n",
    "        X_test_sel = X_test_scaled[:, selected_idx]\n",
    "        \n",
    "        # --- Inner Cross-validation (for model optimization using RandomizedSearchCV) ---\n",
    "        skf_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for inner_train_idx, inner_val_idx in skf_inner.split(X_train_sel, y_train):\n",
    "            X_inner_train, X_inner_val = X_train_sel[inner_train_idx], X_train_sel[inner_val_idx]\n",
    "            y_inner_train, y_inner_val = y_train[inner_train_idx], y_train[inner_val_idx]\n",
    "            \n",
    "            # RandomizedSearch for Random Forest\n",
    "            rf_model = random_search_rf(X_inner_train, y_inner_train)\n",
    "\n",
    "            # --- Train model and get F1 scores for normal (0) and abnormal (1) classes ---\n",
    "            rf_preds = rf_model.predict(X_inner_val)\n",
    "\n",
    "            # F1 scores for both classes (normal and abnormal)\n",
    "            f1_rf = f1_score(y_inner_val, rf_preds, average=None, labels=[0, 1])\n",
    "\n",
    "            # Store results for this fold\n",
    "            rf_results_normal.append(f1_rf[0])\n",
    "            rf_results_abnormal.append(f1_rf[1])\n",
    "        \n",
    "        # --- Final evaluation on the outer test set after optimization ---\n",
    "        rf_model_final = random_search_rf(X_train_sel, y_train)\n",
    "        rf_preds_test = rf_model_final.predict(X_test_sel)\n",
    "\n",
    "        # F1 scores for Random Forest on outer test set\n",
    "        f1_rf_test = f1_score(y_test, rf_preds_test, average=None, labels=[0, 1])\n",
    "\n",
    "        # Print results for outer fold evaluation\n",
    "        print(f\"\\nOuter Fold Evaluation Results for Random Forest:\")\n",
    "        print(f\"Random Forest: Normal F1: {f1_rf_test[0]:.4f} | Abnormal F1: {f1_rf_test[1]:.4f}\")\n",
    "\n",
    "    # --- Final Summary after all outer folds ---\n",
    "    print(\"\\n Final Summary of All Outer Folds for Random Forest:\")\n",
    "    print(f\"Random Forest: Average Normal F1: {np.mean(rf_results_normal):.4f} | Average Abnormal F1: {np.mean(rf_results_abnormal):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a6e8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def outer_cv_pipeline_svm(X, y, feature_selection_method, k_features=2100):\n",
    "    # Outer CV Split\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Randomized Search for SVM\n",
    "    def random_search_svm(X_tr, y_tr):\n",
    "        svm = SVC(random_state=42)\n",
    "        param_dist = {\n",
    "            'C': [0.1],\n",
    "            'kernel': ['rbf'],\n",
    "            'gamma': ['scale'],\n",
    "            'degree': [2],\n",
    "        }\n",
    "        random_search = RandomizedSearchCV(svm, param_distributions=param_dist, n_iter=1, cv=3, random_state=42, n_jobs=-1)\n",
    "        random_search.fit(X_tr, y_tr)\n",
    "        return random_search.best_estimator_\n",
    "\n",
    "    # Initialize lists to store results for each fold\n",
    "    svm_results_normal = []\n",
    "    svm_results_abnormal = []\n",
    "\n",
    "    # Outer Cross-validation loop\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # --- Scale the data (fit on training, transform on both train/test) ---\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)  # Fit on training set\n",
    "        X_test_scaled = scaler.transform(X_test)        # Use the same scaler for the test set\n",
    "\n",
    "        # --- Feature Selection using the specified method ---\n",
    "        selected_idx = feature_selection_method(X_train_scaled, y_train, k_features)\n",
    "        X_train_sel = X_train_scaled[:, selected_idx]\n",
    "        X_test_sel = X_test_scaled[:, selected_idx]\n",
    "        \n",
    "        # --- Inner Cross-validation (for model optimization using RandomizedSearchCV) ---\n",
    "        skf_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for inner_train_idx, inner_val_idx in skf_inner.split(X_train_sel, y_train):\n",
    "            X_inner_train, X_inner_val = X_train_sel[inner_train_idx], X_train_sel[inner_val_idx]\n",
    "            y_inner_train, y_inner_val = y_train[inner_train_idx], y_train[inner_val_idx]\n",
    "            \n",
    "            # RandomizedSearch for SVM\n",
    "            svm_model = random_search_svm(X_inner_train, y_inner_train)\n",
    "\n",
    "            # --- Train model and get F1 scores for normal (0) and abnormal (1) classes ---\n",
    "            svm_preds = svm_model.predict(X_inner_val)\n",
    "\n",
    "            # F1 scores for both classes (normal and abnormal)\n",
    "            f1_svm = f1_score(y_inner_val, svm_preds, average=None, labels=[0, 1])\n",
    "\n",
    "            # Store results for this fold\n",
    "            svm_results_normal.append(f1_svm[0])\n",
    "            svm_results_abnormal.append(f1_svm[1])\n",
    "        \n",
    "        # --- Final evaluation on the outer test set after optimization ---\n",
    "        svm_model_final = random_search_svm(X_train_sel, y_train)\n",
    "        svm_preds_test = svm_model_final.predict(X_test_sel)\n",
    "\n",
    "        # F1 scores for SVM on outer test set\n",
    "        f1_svm_test = f1_score(y_test, svm_preds_test, average=None, labels=[0, 1])\n",
    "\n",
    "        # Print results for outer fold evaluation\n",
    "        print(f\"\\nOuter Fold Evaluation Results for SVM:\")\n",
    "        print(f\"SVM: Normal F1: {f1_svm_test[0]:.4f} | Abnormal F1: {f1_svm_test[1]:.4f}\")\n",
    "\n",
    "    # --- Final Summary after all outer folds ---\n",
    "    print(\"\\n Final Summary of All Outer Folds for SVM:\")\n",
    "    print(f\"SVM: Average Normal F1: {np.mean(svm_results_normal):.4f} | Average Abnormal F1: {np.mean(svm_results_abnormal):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1414748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best feature selection method of inner cv is ttest\n",
    "def ttest_selector(X, y, k):\n",
    "    from scipy import stats\n",
    "    import numpy as np\n",
    "    p_values = [stats.ttest_ind(X[y == 0, i], X[y == 1, i])[1] for i in range(X.shape[1])]\n",
    "    return np.argsort(p_values)[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46f707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer Fold Evaluation Results for Random Forest:\n",
      "Random Forest: Normal F1: 0.9164 | Abnormal F1: 0.2424\n",
      "\n",
      "Outer Fold Evaluation Results for Random Forest:\n",
      "Random Forest: Normal F1: 0.9097 | Abnormal F1: 0.1818\n",
      "\n",
      "Outer Fold Evaluation Results for Random Forest:\n",
      "Random Forest: Normal F1: 0.9189 | Abnormal F1: 0.2941\n",
      "\n",
      "Outer Fold Evaluation Results for Random Forest:\n",
      "Random Forest: Normal F1: 0.9220 | Abnormal F1: 0.3429\n",
      "\n",
      "Outer Fold Evaluation Results for Random Forest:\n",
      "Random Forest: Normal F1: 0.9067 | Abnormal F1: 0.0667\n",
      "\n",
      " Final Summary of All Outer Folds for Random Forest:\n",
      "Random Forest: Average Normal F1: 0.9115 | Average Abnormal F1: 0.2004\n"
     ]
    }
   ],
   "source": [
    "# Use Random Forest for evaluation\n",
    "outer_cv_pipeline_rf(X, y, ttest_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1654056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer Fold Evaluation Results for SVM:\n",
      "SVM: Normal F1: 0.9043 | Abnormal F1: 0.0000\n",
      "\n",
      "Outer Fold Evaluation Results for SVM:\n",
      "SVM: Normal F1: 0.9007 | Abnormal F1: 0.0000\n",
      "\n",
      "Outer Fold Evaluation Results for SVM:\n",
      "SVM: Normal F1: 0.9037 | Abnormal F1: 0.0000\n",
      "\n",
      "Outer Fold Evaluation Results for SVM:\n",
      "SVM: Normal F1: 0.9037 | Abnormal F1: 0.0000\n",
      "\n",
      "Outer Fold Evaluation Results for SVM:\n",
      "SVM: Normal F1: 0.9037 | Abnormal F1: 0.0000\n",
      "\n",
      " Final Summary of All Outer Folds for SVM:\n",
      "SVM: Average Normal F1: 0.9032 | Average Abnormal F1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Use SVM for evaluation\n",
    "outer_cv_pipeline_svm(X, y, ttest_selector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
